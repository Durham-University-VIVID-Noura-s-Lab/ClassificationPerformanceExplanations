{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import argparse\n",
    "import pickle as pk\n",
    "import time\n",
    "from re import S\n",
    "import torch\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_utils import *\n",
    "#from src.model_utils import setupTokenizer\n",
    "from src.datasethandler import NarrationDataSet,train_data_permutated_path,test_data_path,DataSetLoader\n",
    "from src.inferenceUtils import PerformanceNarrator\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback,T5Config\n",
    "from src.modeling_bart import BartNarrationModel\n",
    "from src.modeling_t5 import T5NarrationModel\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_performance_description_inference import ClassificationPerformanceNarration\n",
    "trained_model_path = \"Trained_models/trainednarrators/baseline/bart-base/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the narrator\n",
    "narrator = ClassificationPerformanceNarration(model_base = \"facebook/bart-base\",\n",
    "                                              model_base_dir= trained_model_path,\n",
    "                                              class_labels = ['Low',\n",
    "                                                              'High'],\n",
    "                                              is_balance=True,\n",
    "                                              modeltype='baseline',\n",
    "                                              max_preamble_len=160,\n",
    "                                              max_len_trg=185,\n",
    "                                              length_penalty=3.6,\n",
    "                                              beam_size=8,\n",
    "                                              repetition_penalty=1.5,\n",
    "                                              return_top_beams=1,\n",
    "                                              random_state=453,\n",
    "                                              )\n",
    "                                              \n",
    "# Set up the inference model\n",
    "narrator.buildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 453\n"
     ]
    }
   ],
   "source": [
    "# The setup is ready to be used\n",
    "\n",
    "# Sample of the expected format for the performance report\n",
    "performance_report = {'Recall':[\"89.56%\",\"HIGH\"],'Accuracy':[\"40.16%\",\"LOW\"],'AUC':[\"70.16%\",\"HIGH\"]}\n",
    "generatedTexts = narrator.generateTextualExplanation(performance_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On this multi-class classification task, where the test instances are classified under either class Low or class High, the model's performance is summarized by the scores: (a) Accuracy equal to 40.16%; (b) AUC score equal 89.56%. (c) Precision score equals 70.32%. Since there is a disproportionate amount of data between the two class labels, only the precision and Recall scores are important metrics to take into account. From these scores, we can draw the conclusion that this model will likely misclassify only a small portion of all possible test cases.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generatedTexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartPretrainedModel,BartConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrator.narrator.model.generator.config.to_json_file(json_file_path=trained_model_path+'/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = json.load(open(trained_model_path+'/parameters.json'))\n",
    "#state_dict = json.load(open(args.model_base_dir+'/parameters.json'))\n",
    "best_check_point = params_dict['best_check_point']\n",
    "best_check_point_model = best_check_point + '/pytorch_model.bin'\n",
    "state_dict = torch.load(best_check_point_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bconfig = BartConfig.from_json_file(trained_model_path+'/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "zzp = BartPretrainedModel(bconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BartPretrainedModel:\n\tUnexpected key(s) in state_dict: \"generator.final_logits_bias\", \"generator.model.shared.weight\", \"generator.model.encoder.embed_tokens.weight\", \"generator.model.encoder.embed_positions.weight\", \"generator.model.encoder.layers.0.self_attn.k_proj.weight\", \"generator.model.encoder.layers.0.self_attn.k_proj.bias\", \"generator.model.encoder.layers.0.self_attn.v_proj.weight\", \"generator.model.encoder.layers.0.self_attn.v_proj.bias\", \"generator.model.encoder.layers.0.self_attn.q_proj.weight\", \"generator.model.encoder.layers.0.self_attn.q_proj.bias\", \"generator.model.encoder.layers.0.self_attn.out_proj.weight\", \"generator.model.encoder.layers.0.self_attn.out_proj.bias\", \"generator.model.encoder.layers.0.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.0.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.0.fc1.weight\", \"generator.model.encoder.layers.0.fc1.bias\", \"generator.model.encoder.layers.0.fc2.weight\", \"generator.model.encoder.layers.0.fc2.bias\", \"generator.model.encoder.layers.0.final_layer_norm.weight\", \"generator.model.encoder.layers.0.final_layer_norm.bias\", \"generator.model.encoder.layers.1.self_attn.k_proj.weight\", \"generator.model.encoder.layers.1.self_attn.k_proj.bias\", \"generator.model.encoder.layers.1.self_attn.v_proj.weight\", \"generator.model.encoder.layers.1.self_attn.v_proj.bias\", \"generator.model.encoder.layers.1.self_attn.q_proj.weight\", \"generator.model.encoder.layers.1.self_attn.q_proj.bias\", \"generator.model.encoder.layers.1.self_attn.out_proj.weight\", \"generator.model.encoder.layers.1.self_attn.out_proj.bias\", \"generator.model.encoder.layers.1.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.1.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.1.fc1.weight\", \"generator.model.encoder.layers.1.fc1.bias\", \"generator.model.encoder.layers.1.fc2.weight\", \"generator.model.encoder.layers.1.fc2.bias\", \"generator.model.encoder.layers.1.final_layer_norm.weight\", \"generator.model.encoder.layers.1.final_layer_norm.bias\", \"generator.model.encoder.layers.2.self_attn.k_proj.weight\", \"generator.model.encoder.layers.2.self_attn.k_proj.bias\", \"generator.model.encoder.layers.2.self_attn.v_proj.weight\", \"generator.model.encoder.layers.2.self_attn.v_proj.bias\", \"generator.model.encoder.layers.2.self_attn.q_proj.weight\", \"generator.model.encoder.layers.2.self_attn.q_proj.bias\", \"generator.model.encoder.layers.2.self_attn.out_proj.weight\", \"generator.model.encoder.layers.2.self_attn.out_proj.bias\", \"generator.model.encoder.layers.2.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.2.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.2.fc1.weight\", \"generator.model.encoder.layers.2.fc1.bias\", \"generator.model.encoder.layers.2.fc2.weight\", \"generator.model.encoder.layers.2.fc2.bias\", \"generator.model.encoder.layers.2.final_layer_norm.weight\", \"generator.model.encoder.layers.2.final_layer_norm.bias\", \"generator.model.encoder.layers.3.self_attn.k_proj.weight\", \"generator.model.encoder.layers.3.self_attn.k_proj.bias\", \"generator.model.encoder.layers.3.self_attn.v_proj.weight\", \"generator.model.encoder.layers.3.self_attn.v_proj.bias\", \"generator.model.encoder.layers.3.self_attn.q_proj.weight\", \"generator.model.encoder.layers.3.self_attn.q_proj.bias\", \"generator.model.encoder.layers.3.self_attn.out_proj.weight\", \"generator.model.encoder.layers.3.self_attn.out_proj.bias\", \"generator.model.encoder.layers.3.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.3.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.3.fc1.weight\", \"generator.model.encoder.layers.3.fc1.bias\", \"generator.model.encoder.layers.3.fc2.weight\", \"generator.model.encoder.layers.3.fc2.bias\", \"generator.model.encoder.layers.3.final_layer_norm.weight\", \"generator.model.encoder.layers.3.final_layer_norm.bias\", \"generator.model.encoder.layers.4.self_attn.k_proj.weight\", \"generator.model.encoder.layers.4.self_attn.k_proj.bias\", \"generator.model.encoder.layers.4.self_attn.v_proj.weight\", \"generator.model.encoder.layers.4.self_attn.v_proj.bias\", \"generator.model.encoder.layers.4.self_attn.q_proj.weight\", \"generator.model.encoder.layers.4.self_attn.q_proj.bias\", \"generator.model.encoder.layers.4.self_attn.out_proj.weight\", \"generator.model.encoder.layers.4.self_attn.out_proj.bias\", \"generator.model.encoder.layers.4.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.4.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.4.fc1.weight\", \"generator.model.encoder.layers.4.fc1.bias\", \"generator.model.encoder.layers.4.fc2.weight\", \"generator.model.encoder.layers.4.fc2.bias\", \"generator.model.encoder.layers.4.final_layer_norm.weight\", \"generator.model.encoder.layers.4.final_layer_norm.bias\", \"generator.model.encoder.layers.5.self_attn.k_proj.weight\", \"generator.model.encoder.layers.5.self_attn.k_proj.bias\", \"generator.model.encoder.layers.5.self_attn.v_proj.weight\", \"generator.model.encoder.layers.5.self_attn.v_proj.bias\", \"generator.model.encoder.layers.5.self_attn.q_proj.weight\", \"generator.model.encoder.layers.5.self_attn.q_proj.bias\", \"generator.model.encoder.layers.5.self_attn.out_proj.weight\", \"generator.model.encoder.layers.5.self_attn.out_proj.bias\", \"generator.model.encoder.layers.5.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.5.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.5.fc1.weight\", \"generator.model.encoder.layers.5.fc1.bias\", \"generator.model.encoder.layers.5.fc2.weight\", \"generator.model.encoder.layers.5.fc2.bias\", \"generator.model.encoder.layers.5.final_layer_norm.weight\", \"generator.model.encoder.layers.5.final_layer_norm.bias\", \"generator.model.encoder.layernorm_embedding.weight\", \"generator.model.encoder.layernorm_embedding.bias\", \"generator.model.decoder.embed_tokens.weight\", \"generator.model.decoder.embed_positions.weight\", \"generator.model.decoder.layers.0.self_attn.k_proj.weight\", \"generator.model.decoder.layers.0.self_attn.k_proj.bias\", \"generator.model.decoder.layers.0.self_attn.v_proj.weight\", \"generator.model.decoder.layers.0.self_attn.v_proj.bias\", \"generator.model.decoder.layers.0.self_attn.q_proj.weight\", \"generator.model.decoder.layers.0.self_attn.q_proj.bias\", \"generator.model.decoder.layers.0.self_attn.out_proj.weight\", \"generator.model.decoder.layers.0.self_attn.out_proj.bias\", \"generator.model.decoder.layers.0.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.0.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.0.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.0.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.0.fc1.weight\", \"generator.model.decoder.layers.0.fc1.bias\", \"generator.model.decoder.layers.0.fc2.weight\", \"generator.model.decoder.layers.0.fc2.bias\", \"generator.model.decoder.layers.0.final_layer_norm.weight\", \"generator.model.decoder.layers.0.final_layer_norm.bias\", \"generator.model.decoder.layers.1.self_attn.k_proj.weight\", \"generator.model.decoder.layers.1.self_attn.k_proj.bias\", \"generator.model.decoder.layers.1.self_attn.v_proj.weight\", \"generator.model.decoder.layers.1.self_attn.v_proj.bias\", \"generator.model.decoder.layers.1.self_attn.q_proj.weight\", \"generator.model.decoder.layers.1.self_attn.q_proj.bias\", \"generator.model.decoder.layers.1.self_attn.out_proj.weight\", \"generator.model.decoder.layers.1.self_attn.out_proj.bias\", \"generator.model.decoder.layers.1.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.1.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.1.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.1.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.1.fc1.weight\", \"generator.model.decoder.layers.1.fc1.bias\", \"generator.model.decoder.layers.1.fc2.weight\", \"generator.model.decoder.layers.1.fc2.bias\", \"generator.model.decoder.layers.1.final_layer_norm.weight\", \"generator.model.decoder.layers.1.final_layer_norm.bias\", \"generator.model.decoder.layers.2.self_attn.k_proj.weight\", \"generator.model.decoder.layers.2.self_attn.k_proj.bias\", \"generator.model.decoder.layers.2.self_attn.v_proj.weight\", \"generator.model.decoder.layers.2.self_attn.v_proj.bias\", \"generator.model.decoder.layers.2.self_attn.q_proj.weight\", \"generator.model.decoder.layers.2.self_attn.q_proj.bias\", \"generator.model.decoder.layers.2.self_attn.out_proj.weight\", \"generator.model.decoder.layers.2.self_attn.out_proj.bias\", \"generator.model.decoder.layers.2.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.2.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.2.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.2.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.2.fc1.weight\", \"generator.model.decoder.layers.2.fc1.bias\", \"generator.model.decoder.layers.2.fc2.weight\", \"generator.model.decoder.layers.2.fc2.bias\", \"generator.model.decoder.layers.2.final_layer_norm.weight\", \"generator.model.decoder.layers.2.final_layer_norm.bias\", \"generator.model.decoder.layers.3.self_attn.k_proj.weight\", \"generator.model.decoder.layers.3.self_attn.k_proj.bias\", \"generator.model.decoder.layers.3.self_attn.v_proj.weight\", \"generator.model.decoder.layers.3.self_attn.v_proj.bias\", \"generator.model.decoder.layers.3.self_attn.q_proj.weight\", \"generator.model.decoder.layers.3.self_attn.q_proj.bias\", \"generator.model.decoder.layers.3.self_attn.out_proj.weight\", \"generator.model.decoder.layers.3.self_attn.out_proj.bias\", \"generator.model.decoder.layers.3.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.3.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.3.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.3.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.3.fc1.weight\", \"generator.model.decoder.layers.3.fc1.bias\", \"generator.model.decoder.layers.3.fc2.weight\", \"generator.model.decoder.layers.3.fc2.bias\", \"generator.model.decoder.layers.3.final_layer_norm.weight\", \"generator.model.decoder.layers.3.final_layer_norm.bias\", \"generator.model.decoder.layers.4.self_attn.k_proj.weight\", \"generator.model.decoder.layers.4.self_attn.k_proj.bias\", \"generator.model.decoder.layers.4.self_attn.v_proj.weight\", \"generator.model.decoder.layers.4.self_attn.v_proj.bias\", \"generator.model.decoder.layers.4.self_attn.q_proj.weight\", \"generator.model.decoder.layers.4.self_attn.q_proj.bias\", \"generator.model.decoder.layers.4.self_attn.out_proj.weight\", \"generator.model.decoder.layers.4.self_attn.out_proj.bias\", \"generator.model.decoder.layers.4.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.4.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.4.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.4.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.4.fc1.weight\", \"generator.model.decoder.layers.4.fc1.bias\", \"generator.model.decoder.layers.4.fc2.weight\", \"generator.model.decoder.layers.4.fc2.bias\", \"generator.model.decoder.layers.4.final_layer_norm.weight\", \"generator.model.decoder.layers.4.final_layer_norm.bias\", \"generator.model.decoder.layers.5.self_attn.k_proj.weight\", \"generator.model.decoder.layers.5.self_attn.k_proj.bias\", \"generator.model.decoder.layers.5.self_attn.v_proj.weight\", \"generator.model.decoder.layers.5.self_attn.v_proj.bias\", \"generator.model.decoder.layers.5.self_attn.q_proj.weight\", \"generator.model.decoder.layers.5.self_attn.q_proj.bias\", \"generator.model.decoder.layers.5.self_attn.out_proj.weight\", \"generator.model.decoder.layers.5.self_attn.out_proj.bias\", \"generator.model.decoder.layers.5.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.5.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.5.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.5.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.5.fc1.weight\", \"generator.model.decoder.layers.5.fc1.bias\", \"generator.model.decoder.layers.5.fc2.weight\", \"generator.model.decoder.layers.5.fc2.bias\", \"generator.model.decoder.layers.5.final_layer_norm.weight\", \"generator.model.decoder.layers.5.final_layer_norm.bias\", \"generator.model.decoder.layernorm_embedding.weight\", \"generator.model.decoder.layernorm_embedding.bias\", \"generator.lm_head.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-997efcc720b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzzp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/annotation/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BartPretrainedModel:\n\tUnexpected key(s) in state_dict: \"generator.final_logits_bias\", \"generator.model.shared.weight\", \"generator.model.encoder.embed_tokens.weight\", \"generator.model.encoder.embed_positions.weight\", \"generator.model.encoder.layers.0.self_attn.k_proj.weight\", \"generator.model.encoder.layers.0.self_attn.k_proj.bias\", \"generator.model.encoder.layers.0.self_attn.v_proj.weight\", \"generator.model.encoder.layers.0.self_attn.v_proj.bias\", \"generator.model.encoder.layers.0.self_attn.q_proj.weight\", \"generator.model.encoder.layers.0.self_attn.q_proj.bias\", \"generator.model.encoder.layers.0.self_attn.out_proj.weight\", \"generator.model.encoder.layers.0.self_attn.out_proj.bias\", \"generator.model.encoder.layers.0.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.0.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.0.fc1.weight\", \"generator.model.encoder.layers.0.fc1.bias\", \"generator.model.encoder.layers.0.fc2.weight\", \"generator.model.encoder.layers.0.fc2.bias\", \"generator.model.encoder.layers.0.final_layer_norm.weight\", \"generator.model.encoder.layers.0.final_layer_norm.bias\", \"generator.model.encoder.layers.1.self_attn.k_proj.weight\", \"generator.model.encoder.layers.1.self_attn.k_proj.bias\", \"generator.model.encoder.layers.1.self_attn.v_proj.weight\", \"generator.model.encoder.layers.1.self_attn.v_proj.bias\", \"generator.model.encoder.layers.1.self_attn.q_proj.weight\", \"generator.model.encoder.layers.1.self_attn.q_proj.bias\", \"generator.model.encoder.layers.1.self_attn.out_proj.weight\", \"generator.model.encoder.layers.1.self_attn.out_proj.bias\", \"generator.model.encoder.layers.1.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.1.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.1.fc1.weight\", \"generator.model.encoder.layers.1.fc1.bias\", \"generator.model.encoder.layers.1.fc2.weight\", \"generator.model.encoder.layers.1.fc2.bias\", \"generator.model.encoder.layers.1.final_layer_norm.weight\", \"generator.model.encoder.layers.1.final_layer_norm.bias\", \"generator.model.encoder.layers.2.self_attn.k_proj.weight\", \"generator.model.encoder.layers.2.self_attn.k_proj.bias\", \"generator.model.encoder.layers.2.self_attn.v_proj.weight\", \"generator.model.encoder.layers.2.self_attn.v_proj.bias\", \"generator.model.encoder.layers.2.self_attn.q_proj.weight\", \"generator.model.encoder.layers.2.self_attn.q_proj.bias\", \"generator.model.encoder.layers.2.self_attn.out_proj.weight\", \"generator.model.encoder.layers.2.self_attn.out_proj.bias\", \"generator.model.encoder.layers.2.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.2.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.2.fc1.weight\", \"generator.model.encoder.layers.2.fc1.bias\", \"generator.model.encoder.layers.2.fc2.weight\", \"generator.model.encoder.layers.2.fc2.bias\", \"generator.model.encoder.layers.2.final_layer_norm.weight\", \"generator.model.encoder.layers.2.final_layer_norm.bias\", \"generator.model.encoder.layers.3.self_attn.k_proj.weight\", \"generator.model.encoder.layers.3.self_attn.k_proj.bias\", \"generator.model.encoder.layers.3.self_attn.v_proj.weight\", \"generator.model.encoder.layers.3.self_attn.v_proj.bias\", \"generator.model.encoder.layers.3.self_attn.q_proj.weight\", \"generator.model.encoder.layers.3.self_attn.q_proj.bias\", \"generator.model.encoder.layers.3.self_attn.out_proj.weight\", \"generator.model.encoder.layers.3.self_attn.out_proj.bias\", \"generator.model.encoder.layers.3.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.3.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.3.fc1.weight\", \"generator.model.encoder.layers.3.fc1.bias\", \"generator.model.encoder.layers.3.fc2.weight\", \"generator.model.encoder.layers.3.fc2.bias\", \"generator.model.encoder.layers.3.final_layer_norm.weight\", \"generator.model.encoder.layers.3.final_layer_norm.bias\", \"generator.model.encoder.layers.4.self_attn.k_proj.weight\", \"generator.model.encoder.layers.4.self_attn.k_proj.bias\", \"generator.model.encoder.layers.4.self_attn.v_proj.weight\", \"generator.model.encoder.layers.4.self_attn.v_proj.bias\", \"generator.model.encoder.layers.4.self_attn.q_proj.weight\", \"generator.model.encoder.layers.4.self_attn.q_proj.bias\", \"generator.model.encoder.layers.4.self_attn.out_proj.weight\", \"generator.model.encoder.layers.4.self_attn.out_proj.bias\", \"generator.model.encoder.layers.4.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.4.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.4.fc1.weight\", \"generator.model.encoder.layers.4.fc1.bias\", \"generator.model.encoder.layers.4.fc2.weight\", \"generator.model.encoder.layers.4.fc2.bias\", \"generator.model.encoder.layers.4.final_layer_norm.weight\", \"generator.model.encoder.layers.4.final_layer_norm.bias\", \"generator.model.encoder.layers.5.self_attn.k_proj.weight\", \"generator.model.encoder.layers.5.self_attn.k_proj.bias\", \"generator.model.encoder.layers.5.self_attn.v_proj.weight\", \"generator.model.encoder.layers.5.self_attn.v_proj.bias\", \"generator.model.encoder.layers.5.self_attn.q_proj.weight\", \"generator.model.encoder.layers.5.self_attn.q_proj.bias\", \"generator.model.encoder.layers.5.self_attn.out_proj.weight\", \"generator.model.encoder.layers.5.self_attn.out_proj.bias\", \"generator.model.encoder.layers.5.self_attn_layer_norm.weight\", \"generator.model.encoder.layers.5.self_attn_layer_norm.bias\", \"generator.model.encoder.layers.5.fc1.weight\", \"generator.model.encoder.layers.5.fc1.bias\", \"generator.model.encoder.layers.5.fc2.weight\", \"generator.model.encoder.layers.5.fc2.bias\", \"generator.model.encoder.layers.5.final_layer_norm.weight\", \"generator.model.encoder.layers.5.final_layer_norm.bias\", \"generator.model.encoder.layernorm_embedding.weight\", \"generator.model.encoder.layernorm_embedding.bias\", \"generator.model.decoder.embed_tokens.weight\", \"generator.model.decoder.embed_positions.weight\", \"generator.model.decoder.layers.0.self_attn.k_proj.weight\", \"generator.model.decoder.layers.0.self_attn.k_proj.bias\", \"generator.model.decoder.layers.0.self_attn.v_proj.weight\", \"generator.model.decoder.layers.0.self_attn.v_proj.bias\", \"generator.model.decoder.layers.0.self_attn.q_proj.weight\", \"generator.model.decoder.layers.0.self_attn.q_proj.bias\", \"generator.model.decoder.layers.0.self_attn.out_proj.weight\", \"generator.model.decoder.layers.0.self_attn.out_proj.bias\", \"generator.model.decoder.layers.0.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.0.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.0.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.0.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.0.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.0.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.0.fc1.weight\", \"generator.model.decoder.layers.0.fc1.bias\", \"generator.model.decoder.layers.0.fc2.weight\", \"generator.model.decoder.layers.0.fc2.bias\", \"generator.model.decoder.layers.0.final_layer_norm.weight\", \"generator.model.decoder.layers.0.final_layer_norm.bias\", \"generator.model.decoder.layers.1.self_attn.k_proj.weight\", \"generator.model.decoder.layers.1.self_attn.k_proj.bias\", \"generator.model.decoder.layers.1.self_attn.v_proj.weight\", \"generator.model.decoder.layers.1.self_attn.v_proj.bias\", \"generator.model.decoder.layers.1.self_attn.q_proj.weight\", \"generator.model.decoder.layers.1.self_attn.q_proj.bias\", \"generator.model.decoder.layers.1.self_attn.out_proj.weight\", \"generator.model.decoder.layers.1.self_attn.out_proj.bias\", \"generator.model.decoder.layers.1.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.1.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.1.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.1.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.1.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.1.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.1.fc1.weight\", \"generator.model.decoder.layers.1.fc1.bias\", \"generator.model.decoder.layers.1.fc2.weight\", \"generator.model.decoder.layers.1.fc2.bias\", \"generator.model.decoder.layers.1.final_layer_norm.weight\", \"generator.model.decoder.layers.1.final_layer_norm.bias\", \"generator.model.decoder.layers.2.self_attn.k_proj.weight\", \"generator.model.decoder.layers.2.self_attn.k_proj.bias\", \"generator.model.decoder.layers.2.self_attn.v_proj.weight\", \"generator.model.decoder.layers.2.self_attn.v_proj.bias\", \"generator.model.decoder.layers.2.self_attn.q_proj.weight\", \"generator.model.decoder.layers.2.self_attn.q_proj.bias\", \"generator.model.decoder.layers.2.self_attn.out_proj.weight\", \"generator.model.decoder.layers.2.self_attn.out_proj.bias\", \"generator.model.decoder.layers.2.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.2.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.2.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.2.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.2.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.2.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.2.fc1.weight\", \"generator.model.decoder.layers.2.fc1.bias\", \"generator.model.decoder.layers.2.fc2.weight\", \"generator.model.decoder.layers.2.fc2.bias\", \"generator.model.decoder.layers.2.final_layer_norm.weight\", \"generator.model.decoder.layers.2.final_layer_norm.bias\", \"generator.model.decoder.layers.3.self_attn.k_proj.weight\", \"generator.model.decoder.layers.3.self_attn.k_proj.bias\", \"generator.model.decoder.layers.3.self_attn.v_proj.weight\", \"generator.model.decoder.layers.3.self_attn.v_proj.bias\", \"generator.model.decoder.layers.3.self_attn.q_proj.weight\", \"generator.model.decoder.layers.3.self_attn.q_proj.bias\", \"generator.model.decoder.layers.3.self_attn.out_proj.weight\", \"generator.model.decoder.layers.3.self_attn.out_proj.bias\", \"generator.model.decoder.layers.3.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.3.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.3.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.3.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.3.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.3.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.3.fc1.weight\", \"generator.model.decoder.layers.3.fc1.bias\", \"generator.model.decoder.layers.3.fc2.weight\", \"generator.model.decoder.layers.3.fc2.bias\", \"generator.model.decoder.layers.3.final_layer_norm.weight\", \"generator.model.decoder.layers.3.final_layer_norm.bias\", \"generator.model.decoder.layers.4.self_attn.k_proj.weight\", \"generator.model.decoder.layers.4.self_attn.k_proj.bias\", \"generator.model.decoder.layers.4.self_attn.v_proj.weight\", \"generator.model.decoder.layers.4.self_attn.v_proj.bias\", \"generator.model.decoder.layers.4.self_attn.q_proj.weight\", \"generator.model.decoder.layers.4.self_attn.q_proj.bias\", \"generator.model.decoder.layers.4.self_attn.out_proj.weight\", \"generator.model.decoder.layers.4.self_attn.out_proj.bias\", \"generator.model.decoder.layers.4.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.4.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.4.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.4.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.4.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.4.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.4.fc1.weight\", \"generator.model.decoder.layers.4.fc1.bias\", \"generator.model.decoder.layers.4.fc2.weight\", \"generator.model.decoder.layers.4.fc2.bias\", \"generator.model.decoder.layers.4.final_layer_norm.weight\", \"generator.model.decoder.layers.4.final_layer_norm.bias\", \"generator.model.decoder.layers.5.self_attn.k_proj.weight\", \"generator.model.decoder.layers.5.self_attn.k_proj.bias\", \"generator.model.decoder.layers.5.self_attn.v_proj.weight\", \"generator.model.decoder.layers.5.self_attn.v_proj.bias\", \"generator.model.decoder.layers.5.self_attn.q_proj.weight\", \"generator.model.decoder.layers.5.self_attn.q_proj.bias\", \"generator.model.decoder.layers.5.self_attn.out_proj.weight\", \"generator.model.decoder.layers.5.self_attn.out_proj.bias\", \"generator.model.decoder.layers.5.self_attn_layer_norm.weight\", \"generator.model.decoder.layers.5.self_attn_layer_norm.bias\", \"generator.model.decoder.layers.5.encoder_attn.k_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.k_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn.v_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.v_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn.q_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.q_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn.out_proj.weight\", \"generator.model.decoder.layers.5.encoder_attn.out_proj.bias\", \"generator.model.decoder.layers.5.encoder_attn_layer_norm.weight\", \"generator.model.decoder.layers.5.encoder_attn_layer_norm.bias\", \"generator.model.decoder.layers.5.fc1.weight\", \"generator.model.decoder.layers.5.fc1.bias\", \"generator.model.decoder.layers.5.fc2.weight\", \"generator.model.decoder.layers.5.fc2.bias\", \"generator.model.decoder.layers.5.final_layer_norm.weight\", \"generator.model.decoder.layers.5.final_layer_norm.bias\", \"generator.model.decoder.layernorm_embedding.weight\", \"generator.model.decoder.layernorm_embedding.bias\", \"generator.lm_head.weight\". "
     ]
    }
   ],
   "source": [
    "zzp.load_state_dict(state_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4aea246828f75a58a93204fce55d322b87a38415c2742fb8a88040418150f4d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('annotation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
