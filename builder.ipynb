{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import argparse\n",
    "import pickle as pk\n",
    "import time\n",
    "from re import S\n",
    "import torch\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_utils import *\n",
    "#from src.model_utils import setupTokenizer\n",
    "from src.datasethandler import NarrationDataSet\n",
    "from src.inferenceUtils import PerformanceNarrator\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback,T5Config\n",
    "from src.modeling_bart import BartNarrationModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from modeling_t5 import DataNarration\n",
    "from SelfAttentionBasedTableEncoder import (CollapsedMetricsTableEncoder,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pk.load(open('dataset/train_dataset_new.dat', 'rb'))\n",
    "\n",
    "#Load the test set\n",
    "test_data = json.load(open('dataset/test set.json'))\n",
    "test_sample = []\n",
    "eval_tables = []\n",
    "for pc in test_data:\n",
    "    test_sample.append(processInputTableAndNarrations(\n",
    "        pc, identical_metrics=identicals))\n",
    "\n",
    "\n",
    "rtest_sample = []\n",
    "reval_tables = []\n",
    "for pc in test_data:\n",
    "    rtest_sample.append(processInputTableAndNarrations(\n",
    "        pc, identical_metrics=identicals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,529 training samples\n",
      "  100 validation samples\n"
     ]
    }
   ],
   "source": [
    "modelbase = 't5-base'\n",
    "# Process the data and set up the tokenizer\n",
    "narrationdataset = NarrationDataSet(modelbase,\n",
    "                                    max_preamble_len=160,\n",
    "                                    max_len_trg=185, max_rate_toks=8,\n",
    "                                    lower_narrations=True,\n",
    "                                    process_target=True)\n",
    "\n",
    "narrationdataset.fit(processed, test_sample)\n",
    "\n",
    "dataset = narrationdataset.train_dataset\n",
    "test_dataset = narrationdataset.test_dataset\n",
    "tokenizer = tokenizer_ = narrationdataset.tokenizer_\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset, test_dataset\n",
    "\n",
    "\n",
    "train_size = int(len(dataset))\n",
    "val_size = int(len(test_dataset))\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_utils import setupTokenizer\n",
    "\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = train_arguments = {'output_dir':'TrainModels/','warmup_ratio':0.2,\n",
    "'per_device_train_batch_size':8,'num_train_epochs':2,\n",
    "'lr_scheduler_type':'cosine','learning_rate':5e-5,'evaluation_strategy':'steps','logging_steps':500,'seed':456}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "from src.trainer_utils import getTrainingArguments,CustomTrainerFusion\n",
    "def get_model(dataset, model_type):\n",
    "    def getModel():\n",
    "        if 'bart' in dataset.modelbase:\n",
    "            return BartNarrationModel(\n",
    "            vocab_size=len(dataset.tokenizer_), model_type=model_type,\n",
    "            modelbase=dataset.modelbase,)\n",
    "        else:\n",
    "            return T5NarrationModel(\n",
    "            vocab_size=len(dataset.tokenizer_), model_type=model_type,\n",
    "            modelbase=dataset.modelbase,)\n",
    "    return getModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainerFusion(Trainer):\n",
    "    vocab_size: int\n",
    "    scale_loss: bool = False\n",
    "    prev_seq_loss = []\n",
    "    ce_loss = []\n",
    "    total_loss =[]\n",
    "    device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    \n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        comp_input =  inputs\n",
    "        outputs = model(comp_input,)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 456\n",
      "loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /home/essel/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /home/essel/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earlyfusion\n",
      "Early Fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DataNarration.\n",
      "\n",
      "Some weights of DataNarration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.relative_attention_for_table.mask', 'encoder.relative_attention_for_table.query.bias', 'encoder.relative_attention_for_table.value.weight', 'encoder.relative_attention_for_table.key.bias', 'encoder.relative_attention_for_table.Er', 'encoder.relative_attention_for_table.key.weight', 'encoder.relative_attention_for_table.query.weight', 'encoder.relative_attention_for_table.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /home/essel/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /home/essel/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earlyfusion\n",
      "Early Fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DataNarration.\n",
      "\n",
      "Some weights of DataNarration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.relative_attention_for_table.mask', 'encoder.relative_attention_for_table.query.bias', 'encoder.relative_attention_for_table.value.weight', 'encoder.relative_attention_for_table.key.bias', 'encoder.relative_attention_for_table.Er', 'encoder.relative_attention_for_table.key.weight', 'encoder.relative_attention_for_table.query.weight', 'encoder.relative_attention_for_table.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 4529\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1134\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxainarratives\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/essel/caspian_PMN/ClassificationPerformanceExplanations/wandb/run-20220613_031329-23q40isx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xainarratives/huggingface/runs/23q40isx\" target=\"_blank\">TrainModels/</a></strong> to <a href=\"https://wandb.ai/xainarratives/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6757, 'learning_rate': 3.9631510349466016e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to TrainModels/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5913516283035278, 'eval_runtime': 0.7123, 'eval_samples_per_second': 140.394, 'eval_steps_per_second': 18.251, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8597, 'learning_rate': 2.6448087310511516e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to TrainModels/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.450796365737915, 'eval_runtime': 0.6898, 'eval_samples_per_second': 144.972, 'eval_steps_per_second': 18.846, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [TrainModels/checkpoint-500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from TrainModels/checkpoint-1000 (score: 1.450796365737915).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 299.533, 'train_samples_per_second': 30.24, 'train_steps_per_second': 3.786, 'train_loss': 2.651685401876137, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1134, training_loss=2.651685401876137, metrics={'train_runtime': 299.533, 'train_samples_per_second': 30.24, 'train_steps_per_second': 3.786, 'train_loss': 2.651685401876137, 'epoch': 2.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(456)\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Build actual trainingArgument object\n",
    "training_arguments = getTrainingArguments(train_arguments)\n",
    "\n",
    "getModel = get_model(narrationdataset,model_type='earlyfusion')\n",
    "\n",
    "\n",
    "trainer = CustomTrainerFusion(model_init=getModel,\n",
    "                        args=training_arguments,\n",
    "                        train_dataset=narrationdataset.train_dataset,\n",
    "                        eval_dataset=narrationdataset.test_dataset,\n",
    "                        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrator = PerformanceNarrator(trainer.model,narrationdataset,device,sampling=False,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.unsqueeze??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 160])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['preamble_tokens'].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = test_sample[40]\n",
    "seed = 456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 456\n"
     ]
    }
   ],
   "source": [
    "outt=narrator.generateNarration(example, seed,  max_length=190,\n",
    "                          length_penalty=8.6, beam_size=10,\n",
    "                          repetition_penalty= 1.5,\n",
    "                           return_top_beams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The model has an accuracy of 74.67%, an AUC score of 73.99%, and an F2score of 66.21%. From these scores, we can see that the model performs very well in terms of correctly predicting the true labels for a number of test cases belonging to any of the class labels. Furthermore, the specificity score achieved is equal to 84.17%. These scores indicate that this model will not be able to correctly identify the correct label for the majority of all test instances.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The performance of the model on this binary classification problem (where a given test observation is labeled as either #CA or #CB or #CC ) was evaluated based on the metrics: recall, AUC, accuracy, precision, and recall. The scores achieved by the classifier are very high, indicating that it will be effective in terms of its prediction decisions for several test cases with only a small margin of error.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outt"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4aea246828f75a58a93204fce55d322b87a38415c2742fb8a88040418150f4d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('annotation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
